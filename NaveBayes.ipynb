{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuoSjqqlSiqsN0qsd4kIZs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaksonPascoal/Algebra_Linear_Estudos/blob/main/NaveBayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Naive Bayes Ã© uma famÃ­lia de algoritmos de classificaÃ§Ã£o baseados no Teorema de Bayes, sendo particularmente Ãºteis em problemas de classificaÃ§Ã£o probabilÃ­stica. O adjetivo \"naive\" (ingÃªnuo) vem do fato de que esses algoritmos assumem uma independÃªncia condicional entre as variÃ¡veis, o que na prÃ¡tica raramente acontece, mas ainda assim, os algoritmos Naive Bayes podem ser extremamente eficazes. Vamos dividir a explicaÃ§Ã£o em sua histÃ³ria, matemÃ¡tica por trÃ¡s, variantes e aplicaÃ§Ãµes prÃ¡ticas.\n",
        "\n",
        "1. HistÃ³ria\n",
        "O Naive Bayes remonta ao desenvolvimento do Teorema de Bayes, nomeado apÃ³s o matemÃ¡tico Thomas Bayes (1702â€“1761), que formulou o teorema fundamental sobre a probabilidade condicional. O teorema foi publicado postumamente em 1763 e estabelece uma maneira de atualizar as probabilidades Ã  medida que novas evidÃªncias surgem. Embora o teorema tenha sido formulado no sÃ©culo XVIII, os algoritmos Naive Bayes sÃ³ ganharam destaque com o desenvolvimento da aprendizagem de mÃ¡quina e dos classificadores probabilÃ­sticos no sÃ©culo XX.\n",
        "\n",
        "A abordagem ingÃªnua de Bayes comeÃ§ou a ser amplamente explorada em aprendizado de mÃ¡quina e ciÃªncia da computaÃ§Ã£o a partir das dÃ©cadas de 1950 e 1960, principalmente em sistemas de detecÃ§Ã£o de spam e classificaÃ§Ã£o de texto.\n",
        "\n",
        "2. Teoria e MatemÃ¡tica\n",
        "O Naive Bayes Ã© baseado no Teorema de Bayes, que Ã© dado pela fÃ³rmula:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "=\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "â‹…\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        ")\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "P(Aâˆ£B)=\n",
        "P(B)\n",
        "P(Bâˆ£A)â‹…P(A)\n",
        "â€‹\n",
        "\n",
        "Onde:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "P(Aâˆ£B) Ã© a probabilidade de\n",
        "ğ´\n",
        "A ocorrer dado que\n",
        "ğµ\n",
        "B ocorreu (probabilidade posterior).\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "P(Bâˆ£A) Ã© a probabilidade de\n",
        "ğµ\n",
        "B dado\n",
        "ğ´\n",
        "A (probabilidade da verossimilhanÃ§a).\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        ")\n",
        "P(A) Ã© a probabilidade de\n",
        "ğ´\n",
        "A ocorrer independentemente de\n",
        "ğµ\n",
        "B (probabilidade a priori).\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "P(B) Ã© a probabilidade de\n",
        "ğµ\n",
        "B ocorrer.\n",
        "O Naive Bayes usa esse princÃ­pio para classificar uma nova instÃ¢ncia de dados\n",
        "ğ‘¥\n",
        "x, atribuindo-a Ã  classe\n",
        "ğ¶\n",
        "ğ‘˜\n",
        "C\n",
        "k\n",
        "â€‹\n",
        "  que maximiza a probabilidade posterior\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ¶\n",
        "ğ‘˜\n",
        "âˆ£\n",
        "ğ‘¥\n",
        ")\n",
        "P(C\n",
        "k\n",
        "â€‹\n",
        " âˆ£x). O classificador assume que todas as caracterÃ­sticas\n",
        "ğ‘¥\n",
        "1\n",
        ",\n",
        "ğ‘¥\n",
        "2\n",
        ",\n",
        ".\n",
        ".\n",
        ".\n",
        ",\n",
        "ğ‘¥\n",
        "ğ‘›\n",
        "x\n",
        "1\n",
        "â€‹\n",
        " ,x\n",
        "2\n",
        "â€‹\n",
        " ,...,x\n",
        "n\n",
        "â€‹\n",
        "  sÃ£o condicionalmente independentes entre si, dada a classe\n",
        "ğ¶\n",
        "ğ‘˜\n",
        "C\n",
        "k\n",
        "â€‹\n",
        " . Isso nos dÃ¡ a fÃ³rmula:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ¶\n",
        "ğ‘˜\n",
        "âˆ£\n",
        "ğ‘¥\n",
        ")\n",
        "âˆ\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ¶\n",
        "ğ‘˜\n",
        ")\n",
        "âˆ\n",
        "ğ‘–\n",
        "=\n",
        "1\n",
        "ğ‘›\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¥\n",
        "ğ‘–\n",
        "âˆ£\n",
        "ğ¶\n",
        "ğ‘˜\n",
        ")\n",
        "P(C\n",
        "k\n",
        "â€‹\n",
        " âˆ£x)âˆP(C\n",
        "k\n",
        "â€‹\n",
        " )\n",
        "i=1\n",
        "âˆ\n",
        "n\n",
        "â€‹\n",
        " P(x\n",
        "i\n",
        "â€‹\n",
        " âˆ£C\n",
        "k\n",
        "â€‹\n",
        " )\n",
        "3. Variantes do Naive Bayes\n",
        "Existem diferentes tipos de classificadores Naive Bayes, que variam dependendo do tipo de distribuiÃ§Ã£o das variÃ¡veis independentes.\n",
        "\n",
        "Gaussian Naive Bayes: Usado quando as variÃ¡veis sÃ£o contÃ­nuas e assume que as variÃ¡veis seguem uma distribuiÃ§Ã£o normal (gaussiana).\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¥\n",
        "ğ‘–\n",
        "âˆ£\n",
        "ğ¶\n",
        "ğ‘˜\n",
        ")\n",
        "=\n",
        "1\n",
        "2\n",
        "ğœ‹\n",
        "ğœ\n",
        "ğ‘˜\n",
        "2\n",
        "exp\n",
        "â¡\n",
        "(\n",
        "âˆ’\n",
        "(\n",
        "ğ‘¥\n",
        "ğ‘–\n",
        "âˆ’\n",
        "ğœ‡\n",
        "ğ‘˜\n",
        ")\n",
        "2\n",
        "2\n",
        "ğœ\n",
        "ğ‘˜\n",
        "2\n",
        ")\n",
        "P(x\n",
        "i\n",
        "â€‹\n",
        " âˆ£C\n",
        "k\n",
        "â€‹\n",
        " )=\n",
        "2Ï€Ïƒ\n",
        "k\n",
        "2\n",
        "â€‹\n",
        "\n",
        "â€‹\n",
        "\n",
        "1\n",
        "â€‹\n",
        " exp(âˆ’\n",
        "2Ïƒ\n",
        "k\n",
        "2\n",
        "â€‹\n",
        "\n",
        "(x\n",
        "i\n",
        "â€‹\n",
        " âˆ’Î¼\n",
        "k\n",
        "â€‹\n",
        " )\n",
        "2\n",
        "\n",
        "â€‹\n",
        " )\n",
        "Aqui\n",
        "ğœ‡\n",
        "ğ‘˜\n",
        "Î¼\n",
        "k\n",
        "â€‹\n",
        "  e\n",
        "ğœ\n",
        "ğ‘˜\n",
        "2\n",
        "Ïƒ\n",
        "k\n",
        "2\n",
        "â€‹\n",
        "  sÃ£o a mÃ©dia e a variÃ¢ncia da variÃ¡vel\n",
        "ğ‘¥\n",
        "ğ‘–\n",
        "x\n",
        "i\n",
        "â€‹\n",
        "  para a classe\n",
        "ğ¶\n",
        "ğ‘˜\n",
        "C\n",
        "k\n",
        "â€‹\n",
        " .\n",
        "\n",
        "Multinomial Naive Bayes: Ã‰ usado principalmente para classificaÃ§Ã£o de texto, onde as variÃ¡veis sÃ£o contagens de palavras. O algoritmo assume que as caracterÃ­sticas sÃ£o distribuÃ­das de acordo com uma distribuiÃ§Ã£o multinomial.\n",
        "\n",
        "Bernoulli Naive Bayes: TambÃ©m usado para classificaÃ§Ã£o de texto, mas aqui as variÃ¡veis sÃ£o binÃ¡rias (ocorrÃªncia ou ausÃªncia de uma palavra em um documento). Ã‰ adequado quando os atributos de entrada sÃ£o booleanos.\n",
        "\n",
        "4. Uso PrÃ¡tico\n",
        "O Naive Bayes Ã© popular devido Ã  sua simplicidade, rapidez e eficiÃªncia, sendo utilizado principalmente em classificaÃ§Ã£o de texto e filtragem de spam. Alguns de seus usos comuns incluem:\n",
        "\n",
        "ClassificaÃ§Ã£o de e-mails: Filtragem de spam Ã© um dos principais casos de uso. O algoritmo pode determinar a probabilidade de um e-mail ser spam com base na frequÃªncia de certas palavras.\n",
        "AnÃ¡lise de sentimentos: ClassificaÃ§Ã£o de textos com base em suas caracterÃ­sticas (positivas ou negativas), muito Ãºtil em reviews de produtos e redes sociais.\n",
        "DetecÃ§Ã£o de fraudes: O Naive Bayes pode ser utilizado em sistemas de detecÃ§Ã£o de fraudes, atribuindo probabilidades a comportamentos suspeitos.\n",
        "RecomendaÃ§Ã£o de filmes ou produtos: Com base em classificaÃ§Ãµes e preferÃªncias de usuÃ¡rios, ele pode inferir o que outro usuÃ¡rio pode gostar.\n",
        "5. Vantagens e Desvantagens\n",
        "Vantagens:\n",
        "Simples e rÃ¡pido: O Naive Bayes Ã© fÃ¡cil de implementar e computacionalmente eficiente.\n",
        "Bom desempenho com muitos atributos: Mesmo quando hÃ¡ muitos atributos (como em problemas de classificaÃ§Ã£o de texto), o Naive Bayes pode ser eficaz.\n",
        "Robustez com dados pequenos: Ele pode se sair bem, mesmo com pequenas quantidades de dados de treinamento.\n",
        "Desvantagens:\n",
        "SuposiÃ§Ã£o de independÃªncia: A suposiÃ§Ã£o de que os atributos sÃ£o condicionalmente independentes pode ser irrealista em muitos cenÃ¡rios, o que pode prejudicar a precisÃ£o.\n",
        "Problemas com dados contÃ­nuos: Embora a variante gaussiana tente resolver isso, o Naive Bayes ainda pode nÃ£o ser adequado para dados contÃ­nuos sem prÃ©-processamento adequado.\n",
        "Zero frequency problem: Quando uma variÃ¡vel categÃ³rica em um novo dado nÃ£o foi observada no conjunto de treinamento, o Naive Bayes atribui uma probabilidade zero, o que pode ser problemÃ¡tico. Isso Ã© resolvido com a suavizaÃ§Ã£o de Laplace."
      ],
      "metadata": {
        "id": "PR3t6QKXnnL_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NZb-QGxnb1w",
        "outputId": "31680038-f989-45ab-ffaa-9f9839bd7b9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AcurÃ¡cia: 0.98\n"
          ]
        }
      ],
      "source": [
        "#implementaÃ§Ã£o do Nave Bayes com o dataset Iris\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Carregar dataset\n",
        "data_iris = load_iris()\n",
        "X = data_iris.data\n",
        "y = data_iris.target\n",
        "\n",
        "# Dividir em dados de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Criar o modelo Gaussian Naive Bayes\n",
        "model = GaussianNB()\n",
        "\n",
        "# Treinar o modelo\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prever no conjunto de teste\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Avaliar o modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'AcurÃ¡cia: {accuracy:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_iris.feature_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEJMsqxGo_-n",
        "outputId": "a502ee16-4d8b-4340-b1c8-87c08e02dfcd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_iris.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPg-C7N7pD8b",
        "outputId": "c82a6f66-f6be-4f55-ec45-c82ac2bd4527"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_iris.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS4E32UZptNL",
        "outputId": "491f8a86-993b-4474-deb2-b31a3699a993"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#implementaÃ§Ã£o com o dataset cancer de mama da propria biblioteca scikit-learn\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Carregar novo dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Dividir em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Criar e treinar o modelo\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prever e avaliar\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'AcurÃ¡cia no novo dataset: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmLY6KReokqT",
        "outputId": "14cbee9b-4e44-416d-875a-9ff5a54a3e16"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AcurÃ¡cia no novo dataset: 0.94\n"
          ]
        }
      ]
    }
  ]
}